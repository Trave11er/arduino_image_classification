{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model v3 (ours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, AvgPool2D\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers.convolutional import DepthwiseConv2D\n",
    "from keras.backend import relu\n",
    "from keras.activations import softmax\n",
    "from keras import regularizers\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "data_dir = Path('/home/gleb/programming/play/tiny_ml/mini_face_dataset')\n",
    "batch_size = 32\n",
    "img_height = 48\n",
    "img_width = 48\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(data_dir / 'train'),\n",
    "  seed=0,\n",
    "  color_mode='grayscale',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  str(data_dir / 'validation'),\n",
    "  seed=0,\n",
    "  color_mode='grayscale',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "num_classes = len(class_names)\n",
    "dict_ = {}\n",
    "for i in range(num_classes):\n",
    "    dict_[i] = class_names[i]\n",
    "\n",
    "model_path = './saved_model_weights_v3/best_model'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(DepthwiseConv2D((3,3),input_shape=(img_width,img_height,1)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(2, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "convLayer01 = Activation('relu')\n",
    "\n",
    "model.add(Conv2D(2, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(convLayer01)\n",
    "convLayer015 = AvgPool2D(pool_size=(2,2))\n",
    "model.add(convLayer015)\n",
    "\n",
    "model.add(Conv2D(4, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(4, (3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "convLayer02 = AvgPool2D(pool_size=(2,2))\n",
    "model.add(convLayer02)\n",
    "\n",
    "model.add(Conv2D(8,(3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "convLayer03 = Activation('relu')\n",
    "\n",
    "model.add(Conv2D(8,(3, 3)))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "convLayer03 = Activation('relu')\n",
    "convLayer04 = AvgPool2D(pool_size=(2,2))\n",
    "model.add(convLayer04)\n",
    "\n",
    "model.add(Flatten())                                 \n",
    "model.add(Dense(5, activation = relu, kernel_regularizer=regularizers.L2(0.05))) \n",
    "model.add(Dense(num_classes, activation = softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.build((None, img_height, img_height, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  predictions = model.predict(images)\n",
    "  max_predictions = np.argmax(predictions, axis=1)\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(f'{dict_[max_predictions[i]]} ({class_names[labels[i]]})\\n{predictions[i][0]:.2f}, {predictions[i][1]:.2f}, {predictions[i][2]:.2f}')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_ = cv2.imread('ghappy.png', 0)\n",
    "input_ = cv2.imread('gfrown.png', 0)\n",
    "input_ = cv2.imread('output/14.png', 0)\n",
    "#input_ = np.zeros((48, 48), dtype=np.uint8)\n",
    "input_ = cv2.resize(input_, (48, 48))\n",
    "plt.imshow(input_.astype(np.uint8))\n",
    "print(input_.shape)\n",
    "input_ = np.expand_dims(input_, axis=0)\n",
    "print(input_.shape)\n",
    "input_tf = tf.convert_to_tensor(input_, dtype=tf.float32)\n",
    "pred = model.predict([input_tf])\n",
    "print(pred*255)\n",
    "print(dict_[np.argmax(pred, axis=1)[0]])\n",
    "#help(tf.convert_to_tensor)\n",
    "print(images[0].shape)\n",
    "with open('foo.txt', 'w') as fid:\n",
    "    for i in range(input_.shape[1]):\n",
    "        for j in range(input_.shape[2]):\n",
    "            fid.write(f'{input_[0][i, j]}, ')\n",
    "input_.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get -qq install xxd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "# Save the model to disk\n",
    "open(\"face_model_prax.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.getsize('face_model_prax.tflite')\n",
    "\n",
    "!echo \"const unsigned char model[] = {\" > model.h\n",
    "!cat face_model_v3.tflite | xxd -i      >> model.h\n",
    "!echo \"};\"                              >> model.h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
